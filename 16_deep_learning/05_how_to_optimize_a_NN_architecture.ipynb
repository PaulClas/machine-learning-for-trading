{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "from joblib import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import Callback, EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4706 entries, 2000-01-03 to 2018-03-27\n",
      "Columns: 3199 entries, A to ZUMZ\n",
      "dtypes: float64(3199)\n",
      "memory usage: 114.9 MB\n"
     ]
    }
   ],
   "source": [
    "prices = (pd.read_hdf('../data/assets.h5', 'quandl/wiki/prices')\n",
    "          .adj_close\n",
    "          .unstack().loc['2007':])\n",
    "prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 120 entries, 2017-12-31 to 2008-01-31\n",
      "Freq: -1M\n",
      "Columns: 2489 entries, A to ZUMZ\n",
      "dtypes: float64(2489)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "returns = (prices\n",
    "           .resample('M')\n",
    "           .last()\n",
    "           .pct_change()\n",
    "           .loc['2008': '2017']\n",
    "           .dropna(axis=1)\n",
    "           .sort_index(ascending=False))\n",
    "returns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAN</th>\n",
       "      <th>AAON</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAWW</th>\n",
       "      <th>ABAX</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCB</th>\n",
       "      <th>...</th>\n",
       "      <th>ZEUS</th>\n",
       "      <th>ZIGO</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZIOP</th>\n",
       "      <th>ZIXI</th>\n",
       "      <th>ZLC</th>\n",
       "      <th>ZMH</th>\n",
       "      <th>ZQK</th>\n",
       "      <th>ZUMZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>-0.032785</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>-0.012970</td>\n",
       "      <td>-0.015246</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>0.016003</td>\n",
       "      <td>0.082528</td>\n",
       "      <td>-0.028226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025832</td>\n",
       "      <td>-0.094092</td>\n",
       "      <td>-0.004545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.044725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.078385</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.041429</td>\n",
       "      <td>0.235625</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>-0.058680</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.107587</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066509</td>\n",
       "      <td>-0.019313</td>\n",
       "      <td>-0.092784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>0.061814</td>\n",
       "      <td>-0.014108</td>\n",
       "      <td>-0.156544</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>-0.176008</td>\n",
       "      <td>0.096808</td>\n",
       "      <td>-0.067629</td>\n",
       "      <td>0.083987</td>\n",
       "      <td>-0.070091</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015261</td>\n",
       "      <td>-0.241042</td>\n",
       "      <td>-0.008180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>-0.008035</td>\n",
       "      <td>0.061466</td>\n",
       "      <td>-0.013832</td>\n",
       "      <td>0.057515</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>-0.060244</td>\n",
       "      <td>-0.014970</td>\n",
       "      <td>-0.033968</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.090808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>-0.039124</td>\n",
       "      <td>-0.079096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>0.082455</td>\n",
       "      <td>-0.111179</td>\n",
       "      <td>-0.043431</td>\n",
       "      <td>-0.035503</td>\n",
       "      <td>-0.125971</td>\n",
       "      <td>0.106251</td>\n",
       "      <td>0.124579</td>\n",
       "      <td>-0.013579</td>\n",
       "      <td>-0.140733</td>\n",
       "      <td>-0.038210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.034067</td>\n",
       "      <td>0.155515</td>\n",
       "      <td>-0.003752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.019685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-31</th>\n",
       "      <td>0.237670</td>\n",
       "      <td>-0.538999</td>\n",
       "      <td>-0.122768</td>\n",
       "      <td>0.162611</td>\n",
       "      <td>0.162053</td>\n",
       "      <td>0.085082</td>\n",
       "      <td>0.020105</td>\n",
       "      <td>0.153454</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>-0.073431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269937</td>\n",
       "      <td>0.026587</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>-0.062060</td>\n",
       "      <td>-0.163399</td>\n",
       "      <td>-0.321053</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>-0.018339</td>\n",
       "      <td>-0.122302</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-30</th>\n",
       "      <td>0.012739</td>\n",
       "      <td>-0.035915</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>-0.097354</td>\n",
       "      <td>0.018502</td>\n",
       "      <td>0.212195</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.099698</td>\n",
       "      <td>-0.010493</td>\n",
       "      <td>-0.067248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135255</td>\n",
       "      <td>-0.062701</td>\n",
       "      <td>0.210708</td>\n",
       "      <td>0.017563</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-0.018088</td>\n",
       "      <td>0.048583</td>\n",
       "      <td>-0.047521</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>0.335245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-31</th>\n",
       "      <td>-0.025482</td>\n",
       "      <td>-0.281452</td>\n",
       "      <td>0.041991</td>\n",
       "      <td>0.213204</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>0.147816</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>-0.204873</td>\n",
       "      <td>-0.017737</td>\n",
       "      <td>0.139290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092010</td>\n",
       "      <td>-0.023548</td>\n",
       "      <td>-0.262420</td>\n",
       "      <td>-0.046073</td>\n",
       "      <td>-0.048544</td>\n",
       "      <td>-0.012755</td>\n",
       "      <td>0.022774</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>-0.107509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-29</th>\n",
       "      <td>-0.095983</td>\n",
       "      <td>-0.104046</td>\n",
       "      <td>0.067251</td>\n",
       "      <td>-0.072472</td>\n",
       "      <td>-0.062605</td>\n",
       "      <td>-0.076389</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.104762</td>\n",
       "      <td>-0.102822</td>\n",
       "      <td>-0.098859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223413</td>\n",
       "      <td>0.086104</td>\n",
       "      <td>0.047365</td>\n",
       "      <td>-0.120684</td>\n",
       "      <td>-0.063636</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>0.180929</td>\n",
       "      <td>-0.036473</td>\n",
       "      <td>-0.055614</td>\n",
       "      <td>-0.085803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-31</th>\n",
       "      <td>-0.078389</td>\n",
       "      <td>-0.059143</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>-0.101917</td>\n",
       "      <td>-0.058173</td>\n",
       "      <td>-0.316640</td>\n",
       "      <td>-0.078938</td>\n",
       "      <td>-0.092303</td>\n",
       "      <td>0.038110</td>\n",
       "      <td>-0.063501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065594</td>\n",
       "      <td>-0.058587</td>\n",
       "      <td>-0.116676</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>-0.226087</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>0.181255</td>\n",
       "      <td>0.110723</td>\n",
       "      <td>-0.210591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 2489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker             A       AAL       AAN      AAON       AAP      AAPL  \\\n",
       "date                                                                     \n",
       "2017-12-31 -0.032785  0.030501  0.056469  0.006859 -0.012970 -0.015246   \n",
       "2017-11-30  0.017786  0.078385  0.025000  0.041429  0.235625  0.016623   \n",
       "2017-10-31  0.061814 -0.014108 -0.156544  0.015228 -0.176008  0.096808   \n",
       "2017-09-30 -0.008035  0.061466 -0.013832  0.057515  0.013928 -0.060244   \n",
       "2017-08-31  0.082455 -0.111179 -0.043431 -0.035503 -0.125971  0.106251   \n",
       "2008-05-31  0.237670 -0.538999 -0.122768  0.162611  0.162053  0.085082   \n",
       "2008-04-30  0.012739 -0.035915  0.178947 -0.097354  0.018502  0.212195   \n",
       "2008-03-31 -0.025482 -0.281452  0.041991  0.213204  0.017068  0.147816   \n",
       "2008-02-29 -0.095983 -0.104046  0.067251 -0.072472 -0.062605 -0.076389   \n",
       "2008-01-31 -0.078389 -0.059143 -0.009270 -0.101917 -0.058173 -0.316640   \n",
       "\n",
       "ticker          AAWW      ABAX       ABC      ABCB    ...         ZEUS  \\\n",
       "date                                                  ...                \n",
       "2017-12-31  0.015584  0.016003  0.082528 -0.028226    ...     0.078815   \n",
       "2017-11-30 -0.058680  0.007025  0.107587  0.035491    ...     0.055085   \n",
       "2017-10-31 -0.067629  0.083987 -0.070091 -0.001043    ...    -0.141818   \n",
       "2017-09-30 -0.014970 -0.033968  0.031153  0.090808    ...     0.205479   \n",
       "2017-08-31  0.124579 -0.013579 -0.140733 -0.038210    ...     0.069057   \n",
       "2008-05-31  0.020105  0.153454  0.021099 -0.073431    ...     0.269937   \n",
       "2008-04-30  0.103273  0.099698 -0.010493 -0.067248    ...     0.135255   \n",
       "2008-03-31  0.086957 -0.204873 -0.017737  0.139290    ...     0.092010   \n",
       "2008-02-29  0.013216 -0.104762 -0.102822 -0.098859    ...     0.223413   \n",
       "2008-01-31 -0.078938 -0.092303  0.038110 -0.063501    ...     0.065594   \n",
       "\n",
       "ticker          ZIGO      ZINC      ZION      ZIOP      ZIXI       ZLC  \\\n",
       "date                                                                     \n",
       "2017-12-31  0.000000  0.000000  0.025832 -0.094092 -0.004545  0.000000   \n",
       "2017-11-30  0.000000  0.000000  0.066509 -0.019313 -0.092784  0.000000   \n",
       "2017-10-31  0.000000  0.000000 -0.015261 -0.241042 -0.008180  0.000000   \n",
       "2017-09-30  0.000000  0.000000  0.080623 -0.039124 -0.079096  0.000000   \n",
       "2017-08-31  0.000000  0.000000 -0.034067  0.155515 -0.003752  0.000000   \n",
       "2008-05-31  0.026587  0.002140 -0.062060 -0.163399 -0.321053  0.051158   \n",
       "2008-04-30 -0.062701  0.210708  0.017563  0.040816 -0.018088  0.048583   \n",
       "2008-03-31 -0.023548 -0.262420 -0.046073 -0.048544 -0.012755  0.022774   \n",
       "2008-02-29  0.086104  0.047365 -0.120684 -0.063636  0.101124  0.180929   \n",
       "2008-01-31 -0.058587 -0.116676  0.172414 -0.067797 -0.226087  0.018680   \n",
       "\n",
       "ticker           ZMH       ZQK      ZUMZ  \n",
       "date                                      \n",
       "2017-12-31  0.000000  0.000000 -0.044725  \n",
       "2017-11-30  0.000000  0.000000  0.235127  \n",
       "2017-10-31  0.000000  0.000000 -0.024862  \n",
       "2017-09-30  0.000000  0.000000  0.453815  \n",
       "2017-08-31  0.000000  0.000000 -0.019685  \n",
       "2008-05-31 -0.018339 -0.122302  0.000477  \n",
       "2008-04-30 -0.047521 -0.008155  0.335245  \n",
       "2008-03-31  0.034135  0.090000 -0.107509  \n",
       "2008-02-29 -0.036473 -0.055614 -0.085803  \n",
       "2008-01-31  0.181255  0.110723 -0.210591  \n",
       "\n",
       "[10 rows x 2489 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.head().append(returns.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(returns)\n",
    "T = 24\n",
    "tcols = list(range(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for i in range(n-T-1):\n",
    "    df = returns.iloc[i:i+T+1]\n",
    "    data = pd.concat([data, (df.reset_index(drop=True).T\n",
    "                             .assign(year=df.index[0].year,\n",
    "                                     month=df.index[0].month))],\n",
    "                     ignore_index=True)\n",
    "data[tcols] = (data[tcols].apply(lambda x: x.clip(lower=x.quantile(.01),\n",
    "                                                  upper=x.quantile(.99))))\n",
    "data['label'] = (data[0] > 0).astype(int)\n",
    "data = pd.get_dummies(data.drop(0, axis=1).apply(\n",
    "    pd.to_numeric), columns=['year', 'month'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236455, 45)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_hdf('data.h5', 'returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom AUC Loss Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.metrics.auc(y_true, y_pred)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up `build_fn` for `keras.wrappers.scikit_learn.KerasClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(dense_layers, activation, dropout):\n",
    "    '''Creates a multi-layer perceptron model\n",
    "    \n",
    "    dense_layers: List of layer sizes; one number per layer\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "    for i, layer_size in enumerate(dense_layers, 1):\n",
    "        if i == 1:\n",
    "            model.add(Dense(layer_size, input_dim=input_dim))\n",
    "            model.add(Activation(activation))\n",
    "        else:\n",
    "            model.add(Dense(layer_size))\n",
    "            model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['binary_accuracy', auc_roc])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Keras with `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'returns')\n",
    "features, label = data.drop('label' , axis=1), data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = .1\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, label,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GridSearch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(make_model, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'dense_layers': [[32], [32, 32], [64], [64, 64], [64, 64, 32], [64, 32], [128]],\n",
    "              'activation'  : ['relu', 'tanh'],\n",
    "              'dropout'     : [.25, .5, .75],\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=clf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='roc_auc',\n",
    "                  cv=cv,\n",
    "                  refit=True,\n",
    "                  return_train_score=True,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=1,\n",
    "                  iid=False,\n",
    "                  error_score=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = dict(callbacks=[EarlyStopping(monitor='auc_roc', \n",
    "                                           patience=300, \n",
    "                                           verbose=1, mode='max')],\n",
    "                  verbose=2,\n",
    "                  epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X=X_train.astype(float), y=y_train, **fit_params)\n",
    "print('\\nBest Score: {:.2%}'.format(gs.best_score_))\n",
    "print('Best Params:\\n', pd.Series(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Score: 50.49%\n",
    "Best Params:\n",
    " activation            tanh\n",
    "dense_layers    [256, 256]\n",
    "dropout               0.25\n",
    "optimizer          RMSprop\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist best model and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_.model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('data.h5') as store:\n",
    "    store.put('X_train', X_train)\n",
    "    store.put('X_test', X_test)\n",
    "    store.put('y_train', y_train)\n",
    "    store.put('y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.222px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
